x-airflow-common: &airflow-common
    build: .
    environment: &airflow-common-env
        AIRFLOW__CORE__EXECUTOR: CeleryExecutor
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://airflow:airflow@mysql/SerhiiB
        AIRFLOW__CELERY__RESULT_BACKEND: db+mysql://airflow:airflow@mysql/SerhiiB
        AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
        AIRFLOW__CORE__FERNET_KEY: "Gk3HXf-0UnqMUbGofpp68KEk_p2yDiOHYWOzNz-veUk="
        AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
        AIRFLOW__CORE__LOAD_EXAMPLES: "true"
        AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"

    volumes:
        - ./dags:/opt/airflow/dags
        - ./logs:/opt/airflow/logs
        - ./plugins:/opt/airflow/plugins

    user: "${AIRFLOW_UID:-50000}:0"
    depends_on: &airflow-common-depends-on
        redis:
            condition: service_healthy
        mysql:
            condition: service_healthy

services:
    mysql:
        image: mysql:8.0
        environment:
            MYSQL_ROOT_PASSWORD: root
            MYSQL_DATABASE: SerhiiB
            MYSQL_USER: airflow
            MYSQL_PASSWORD: airflow
        ports:
            - "3306:3306"
        volumes:
            - mysql-db-volume:/var/lib/mysql
        healthcheck:
            test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
            interval: 10s
            retries: 10
            start_period: 30s
        restart: always

    redis:
        image: arm64v8/redis:7.2
        expose:
            - "6379"
        healthcheck:
            test: ["CMD", "redis-cli", "ping"]
            interval: 10s
            retries: 5
            start_period: 10s
        restart: always

    airflow-webserver:
        <<: *airflow-common
        command: webserver
        ports:
            - "8080:8080"
        healthcheck:
            test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
            interval: 30s
            retries: 5
            start_period: 30s
        restart: always
        depends_on:
            <<: *airflow-common-depends-on
            airflow-init:
                condition: service_completed_successfully

    airflow-scheduler:
        <<: *airflow-common
        command: scheduler
        healthcheck:
            test: ["CMD", "curl", "--fail", "http://localhost:8793/health"]
            interval: 30s
            retries: 5
            start_period: 30s
        restart: always
        depends_on:
            <<: *airflow-common-depends-on
            airflow-init:
                condition: service_completed_successfully

    airflow-worker:
        <<: *airflow-common
        command: celery worker
        healthcheck:
            test: ["CMD-SHELL", "celery -A airflow.providers.celery.executors.celery_executor.app inspect ping"]
            interval: 30s
            retries: 5
            start_period: 30s
        restart: always
        depends_on:
            <<: *airflow-common-depends-on
            airflow-init:
                condition: service_completed_successfully

    airflow-init:
        <<: *airflow-common
        entrypoint: /bin/bash
        command: >
            -c "
            airflow db init &&
            airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
            "
        user: "0:0"
        restart: "no"
        depends_on:
            <<: *airflow-common-depends-on

volumes:
    mysql-db-volume:
